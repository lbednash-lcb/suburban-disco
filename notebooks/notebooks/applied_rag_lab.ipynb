{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35c27d14",
   "metadata": {},
   "source": [
    "One-click ‚ÄúReset & Run‚Äù master cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29cc3e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "CWD: /workspaces/suburban-disco/notebooks/notebooks\n",
      "Repo root: /workspaces/suburban-disco\n",
      "Env loaded: True\n",
      "Using Top Shelf files: ['The_Top_Shelf_Collection_RAG_with_artist_years_filled.csv']\n",
      "‚úÖ Built 129 Top Shelf records.\n",
      "Example snippet:\n",
      " Artist: 10,000 Maniacs | Title: In My Tribe | Genre: Alternative Rock\n",
      "üî¢ Embedding 129 docs‚Ä¶\n",
      "üìê Embeddings shape: (129, 1536)\n",
      "\n",
      "üß† ANSWER:\n",
      " Notable artist: Simon & Garfunkel | Album: Parsley, Sage, Rosemary and Thyme | Genre: Folk Rock. Distinctive detail: The album features a blend of intricate harmonies and poetic lyrics. \n",
      "\n",
      "üîé TOP HITS:\n",
      "- The_Top_Shelf_Collection_RAG_with_artist_years_filled.csv-118 | score=0.401 | Artist: Various Artists | Title: Woodstock - Music from the Original Soundtrack | Genre: Rock/Folk/Blues‚Ä¶\n",
      "- The_Top_Shelf_Collection_RAG_with_artist_years_filled.csv-74 | score=0.397 | Artist: Simon & Garfunkel | Title: Parsley, Sage, Rosemary and Thyme | Genre: Folk Rock‚Ä¶\n",
      "- The_Top_Shelf_Collection_RAG_with_artist_years_filled.csv-109 | score=0.389 | Artist: The Velvet Underground | Title: Loaded | Genre: Rock/Proto-Punk‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "# --- MASTER CELL: safe re-run after any restart ---\n",
    "# It will:\n",
    "# 1) Detect repo_root, 2) load .env, 3) pick only Top Shelf files,\n",
    "# 4) build records, 5) embed in memory, 6) answer one test query.\n",
    "\n",
    "%pip -q install --upgrade numpy pandas openai python-dotenv tiktoken\n",
    "\n",
    "from pathlib import Path\n",
    "import os, json, pandas as pd, numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict\n",
    "\n",
    "# ---------- 1) detect repo root ----------\n",
    "def detect_repo_root(start: Path) -> Path:\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p/\".env\").exists() or (p/\"README.md\").exists() or (p/\"data\").exists():\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "CWD = Path.cwd()\n",
    "repo_root = detect_repo_root(CWD)\n",
    "print(\"CWD:\", CWD)\n",
    "print(\"Repo root:\", repo_root)\n",
    "\n",
    "# ---------- 2) load .env ----------\n",
    "loaded = load_dotenv(repo_root / \".env\", override=True)\n",
    "print(\"Env loaded:\", loaded)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise SystemExit(\"‚ùå OPENAI_API_KEY not found. Put it in repo_root/.env then re-run this cell.\")\n",
    "\n",
    "# ---------- 3) collect ONLY Top Shelf files ----------\n",
    "data_dir = repo_root / \"data\"\n",
    "if not data_dir.exists():\n",
    "    raise SystemExit(f\"‚ùå data folder not found at {data_dir}. Create it and add your files.\")\n",
    "\n",
    "topshelf_csv  = sorted([p for p in data_dir.glob(\"*.csv\")  if \"top\" in p.name.lower() and \"shelf\" in p.name.lower()])\n",
    "topshelf_json = sorted([p for p in data_dir.glob(\"*.json\") if \"top\" in p.name.lower() and \"shelf\" in p.name.lower()])\n",
    "\n",
    "if not (topshelf_csv or topshelf_json):\n",
    "    print(\"‚ö†Ô∏è No Top Shelf files matched. Showing all data files instead:\")\n",
    "    print([f.name for f in data_dir.iterdir()])\n",
    "    raise SystemExit(\"Rename your files to include 'top' and 'shelf', or adjust the filters in this cell.\")\n",
    "\n",
    "print(\"Using Top Shelf files:\", [p.name for p in (topshelf_json + topshelf_csv)])\n",
    "\n",
    "# ---------- 4) build records ----------\n",
    "records: List[Dict] = []\n",
    "\n",
    "def add_record(text: str, rid: str):\n",
    "    text = (text or \"\").strip()\n",
    "    if text:\n",
    "        records.append({\"id\": rid, \"text\": text})\n",
    "\n",
    "def join_item_fields(item: dict) -> str:\n",
    "    # Prefer explicit text/content\n",
    "    if isinstance(item, dict):\n",
    "        txt = (item.get(\"text\") or item.get(\"content\") or \"\").strip()\n",
    "        if txt:\n",
    "            return txt\n",
    "        # Otherwise join string-like fields\n",
    "        parts = []\n",
    "        for k in sorted(item.keys()):\n",
    "            v = item[k]\n",
    "            if isinstance(v, (str, int, float)) and str(v).strip():\n",
    "                parts.append(f\"{k}: {str(v).strip()}\")\n",
    "        return \" | \".join(parts)\n",
    "    return str(item)\n",
    "\n",
    "# JSON first (if present)\n",
    "for jp in topshelf_json:\n",
    "    data = json.loads(jp.read_text(encoding=\"utf-8\"))\n",
    "    if not isinstance(data, list) or not data:\n",
    "        continue\n",
    "    for i, item in enumerate(data):\n",
    "        add_record(join_item_fields(item), f\"{jp.name}-{i}\")\n",
    "\n",
    "# Then CSVs\n",
    "for cp in topshelf_csv:\n",
    "    try:\n",
    "        df = pd.read_csv(cp)\n",
    "    except Exception:\n",
    "        try:\n",
    "            df = pd.read_csv(cp, encoding=\"utf-8\")\n",
    "        except Exception:\n",
    "            df = pd.read_csv(cp, encoding=\"latin-1\")\n",
    "    # Choose columns (auto if not set)\n",
    "    likely = {\"artist\",\"album\",\"title\",\"description\",\"review\",\"genre\",\"notes\",\"track\",\"year\"}\n",
    "    csv_columns_to_join = [c for c in df.columns if c.lower() in likely] or [c for c in df.columns if df[c].dtype==\"object\"]\n",
    "\n",
    "    def row_to_text(row):\n",
    "        parts = []\n",
    "        for c in csv_columns_to_join:\n",
    "            val = row.get(c, \"\")\n",
    "            if pd.notna(val) and str(val).strip():\n",
    "                parts.append(f\"{c}: {str(val).strip()}\")\n",
    "        return \" | \".join(parts)\n",
    "\n",
    "    for i, r in df.iterrows():\n",
    "        add_record(row_to_text(r), f\"{cp.name}-{i}\")\n",
    "\n",
    "if not records:\n",
    "    raise SystemExit(\"‚ùå No records built from Top Shelf files. Check file contents/columns.\")\n",
    "\n",
    "print(f\"‚úÖ Built {len(records)} Top Shelf records.\")\n",
    "print(\"Example snippet:\\n\", records[0][\"text\"][:400])\n",
    "\n",
    "# ---------- 5) embed in memory ----------\n",
    "from openai import OpenAI\n",
    "client = OpenAI()  # reads OPENAI_API_KEY from env\n",
    "\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "MAX_DOCS = min(200, len(records))   # keep first run fast\n",
    "docs = records[:MAX_DOCS]\n",
    "texts = [d[\"text\"] for d in docs]\n",
    "ids   = [d[\"id\"]   for d in docs]\n",
    "\n",
    "def embed_texts(texts):\n",
    "    vecs = []\n",
    "    for t in texts:\n",
    "        e = client.embeddings.create(model=EMBEDDING_MODEL, input=t).data[0].embedding\n",
    "        vecs.append(np.array(e, dtype=np.float32))\n",
    "    return np.vstack(vecs)\n",
    "\n",
    "print(f\"üî¢ Embedding {len(texts)} docs‚Ä¶\")\n",
    "doc_vecs = embed_texts(texts)\n",
    "doc_vecs = doc_vecs / (np.linalg.norm(doc_vecs, axis=1, keepdims=True) + 1e-12)\n",
    "print(\"üìê Embeddings shape:\", doc_vecs.shape)\n",
    "\n",
    "# ---------- 6) ask one test question ----------\n",
    "CHAT_MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "def top_k(query, k=5):\n",
    "    q = client.embeddings.create(model=EMBEDDING_MODEL, input=query).data[0].embedding\n",
    "    q = np.array(q, dtype=np.float32)\n",
    "    q = q / (np.linalg.norm(q) + 1e-12)\n",
    "    sims = doc_vecs @ q\n",
    "    idxs = np.argsort(-sims)[:k]\n",
    "    return [(ids[i], texts[i], float(sims[i])) for i in idxs]\n",
    "\n",
    "def answer_with_context(query, k=5, temperature=0.2):\n",
    "    hits = top_k(query, k=k)\n",
    "    context = \"\\n\\n\".join(f\"- {h[1]}\" for h in hits)\n",
    "    prompt = (\n",
    "        \"You are a precise assistant. Answer strictly using the CONTEXT below. \"\n",
    "        \"If the answer is not in the context, say you don't know.\\n\\n\"\n",
    "        f\"CONTEXT:\\n{context}\\n\\n\"\n",
    "        f\"QUESTION: {query}\\n\\nANSWER:\"\n",
    "    )\n",
    "    resp = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        temperature=temperature,\n",
    "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip(), hits\n",
    "\n",
    "question = \"Name a notable artist or album and its genre from this Top Shelf collection, plus one distinctive detail.\"\n",
    "ans, hits = answer_with_context(question, k=5)\n",
    "print(\"\\nüß† ANSWER:\\n\", ans, \"\\n\")\n",
    "print(\"üîé TOP HITS:\")\n",
    "for hid, htxt, score in hits[:3]:\n",
    "    print(f\"- {hid} | score={score:.3f} | {htxt[:160]}‚Ä¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60bda15",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c152c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /workspaces/suburban-disco/notebooks/notebooks\n",
      "Repo root: /workspaces/suburban-disco\n",
      ".env exists: True ‚Üí /workspaces/suburban-disco/.env\n",
      "data exists: True ‚Üí /workspaces/suburban-disco/data\n",
      "data files: ['top_rated_wines.csv', 'The_Top_Shelf_Collection_RAG_with_artist_years_filled_embeddings.jsonl', 'The_Top_Shelf_Collection_RAG_with_artist_years_filled.csv']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "cwd = Path.cwd()\n",
    "candidates = [cwd, *cwd.parents]\n",
    "repo_root = None\n",
    "for p in candidates:\n",
    "    if (p/\".env\").exists() or (p/\"README.md\").exists():\n",
    "        repo_root = p\n",
    "        break\n",
    "\n",
    "print(\"CWD:\", cwd)\n",
    "print(\"Repo root:\", repo_root)\n",
    "if repo_root:\n",
    "    print(\".env exists:\", (repo_root/\".env\").exists(), \"‚Üí\", repo_root/\".env\")\n",
    "    print(\"data exists:\", (repo_root/\"data\").exists(), \"‚Üí\", repo_root/\"data\")\n",
    "    if (repo_root/\"data\").exists():\n",
    "        print(\"data files:\", [f.name for f in (repo_root/\"data\").iterdir()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabda435",
   "metadata": {},
   "source": [
    "Verify key being read correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2c2aca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts with: sk-sv\n",
      "Total length: 167\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"Starts with:\", key[:5])\n",
    "print(\"Total length:\", len(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed7a20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Notebook CWD: /workspaces/suburban-disco/notebooks/notebooks\n",
      "üì¶ Repo root: /workspaces/suburban-disco\n",
      "üß© .env exists: True ‚Üí /workspaces/suburban-disco/.env\n",
      "üìÅ data exists: True ‚Üí /workspaces/suburban-disco/data\n",
      "üìÑ data files: ['top_rated_wines.csv', 'The_Top_Shelf_Collection_RAG_with_artist_years_filled_embeddings.jsonl', 'The_Top_Shelf_Collection_RAG_with_artist_years_filled.csv']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# 1) Find repo root by walking up until we see a .env OR README.md\n",
    "cwd = Path.cwd()\n",
    "candidates = [cwd, *cwd.parents]\n",
    "repo_root = None\n",
    "for p in candidates:\n",
    "    if (p/\".env\").exists() or (p/\"README.md\").exists():\n",
    "        repo_root = p\n",
    "        break\n",
    "\n",
    "print(\"üîé Notebook CWD:\", cwd)\n",
    "print(\"üì¶ Repo root:\", repo_root)\n",
    "\n",
    "# 2) Show what we have\n",
    "if repo_root:\n",
    "    env_path = repo_root/\".env\"\n",
    "    data_dir = repo_root/\"data\"\n",
    "    print(\"üß© .env exists:\", env_path.exists(), \"‚Üí\", env_path)\n",
    "    print(\"üìÅ data exists:\", data_dir.exists(), \"‚Üí\", data_dir)\n",
    "    if data_dir.exists():\n",
    "        print(\"üìÑ data files:\", [f.name for f in data_dir.iterdir()])\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Could not determine repo root. We‚Äôll assume cwd is correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7410ead",
   "metadata": {},
   "source": [
    "Cell A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7387f6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Env loaded: True\n",
      "OpenAI key set: True\n"
     ]
    }
   ],
   "source": [
    "%pip -q install python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "loaded = load_dotenv(repo_root/\".env\", override=True)\n",
    "print(\"Env loaded:\", loaded)\n",
    "print(\"OpenAI key set:\", bool(os.getenv(\"OPENAI_API_KEY\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "591538ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-<sk-svc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"OPENAI_API_KEY\")[:10])  # just the first 10 chars for privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c86bd6",
   "metadata": {},
   "source": [
    "Cell A.1 - (re)install core packages (safe to re-run)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7121347d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script openai is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip -q install --upgrade numpy pandas openai tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd22b39",
   "metadata": {},
   "source": [
    "Cell B1 ‚Äî build Top Shelf records only (drop-in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1aa02d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'repo_root' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Dict\n\u001b[32m      4\u001b[39m records: List[Dict] = []\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m data_dir = \u001b[43mrepo_root\u001b[49m / \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Only load files that look like \"Top Shelf\"\u001b[39;00m\n\u001b[32m      8\u001b[39m topshelf_json = \u001b[38;5;28msorted\u001b[39m([p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m data_dir.glob(\u001b[33m\"\u001b[39m\u001b[33m*.json\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtop\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m p.name.lower() \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mshelf\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m p.name.lower()])\n",
      "\u001b[31mNameError\u001b[39m: name 'repo_root' is not defined"
     ]
    }
   ],
   "source": [
    "import pathlib, json, pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "records: List[Dict] = []\n",
    "data_dir = repo_root / \"data\"\n",
    "\n",
    "# Only load files that look like \"Top Shelf\"\n",
    "topshelf_json = sorted([p for p in data_dir.glob(\"*.json\") if \"top\" in p.name.lower() and \"shelf\" in p.name.lower()])\n",
    "topshelf_csv  = sorted([p for p in data_dir.glob(\"*.csv\")  if \"top\" in p.name.lower() and \"shelf\" in p.name.lower()])\n",
    "\n",
    "def add_record(text: str, rid: str):\n",
    "    text = (text or \"\").strip()\n",
    "    if text:\n",
    "        records.append({\"id\": rid, \"text\": text})\n",
    "\n",
    "def join_item_fields(item: dict) -> str:\n",
    "    txt = (item.get(\"text\") or item.get(\"content\") or \"\").strip() if isinstance(item, dict) else \"\"\n",
    "    if txt:\n",
    "        return txt\n",
    "    if isinstance(item, dict):\n",
    "        parts = []\n",
    "        for k in sorted(item.keys()):\n",
    "            v = item[k]\n",
    "            if isinstance(v, (str, int, float)) and str(v).strip():\n",
    "                parts.append(f\"{k}: {str(v).strip()}\")\n",
    "        return \" | \".join(parts)\n",
    "    return str(item)\n",
    "\n",
    "used_files = []\n",
    "\n",
    "if topshelf_json:\n",
    "    for jp in topshelf_json:\n",
    "        used_files.append(jp.name)\n",
    "        data = json.loads(jp.read_text(encoding=\"utf-8\"))\n",
    "        assert isinstance(data, list) and data, f\"{jp.name} must be a non-empty JSON list\"\n",
    "        for i, item in enumerate(data):\n",
    "            add_record(join_item_fields(item), f\"{jp.name}-{i}\")\n",
    "\n",
    "elif topshelf_csv:\n",
    "    for cp in topshelf_csv:\n",
    "        used_files.append(cp.name)\n",
    "        try:\n",
    "            df2 = pd.read_csv(cp)\n",
    "        except Exception:\n",
    "            try:\n",
    "                df2 = pd.read_csv(cp, encoding=\"utf-8\")\n",
    "            except Exception:\n",
    "                df2 = pd.read_csv(cp, encoding=\"latin-1\")\n",
    "\n",
    "        # If you know exact column names, set them here:\n",
    "        csv_columns_to_join = None  # e.g., [\"artist\",\"album\",\"genre\",\"description\"]\n",
    "        if csv_columns_to_join is None:\n",
    "            likely = {\"artist\",\"album\",\"title\",\"description\",\"review\",\"genre\",\"notes\",\"track\",\"year\"}\n",
    "            csv_columns_to_join = [c for c in df2.columns if c.lower() in likely] or \\\n",
    "                                  [c for c in df2.columns if df2[c].dtype == \"object\"]\n",
    "\n",
    "        def row_to_text(row):\n",
    "            parts = []\n",
    "            for c in csv_columns_to_join:\n",
    "                val = row.get(c, \"\")\n",
    "                if pd.notna(val) and str(val).strip():\n",
    "                    parts.append(f\"{c}: {str(val).strip()}\")\n",
    "            return \" | \".join(parts)\n",
    "\n",
    "        for i, r in df2.iterrows():\n",
    "            add_record(row_to_text(r), f\"{cp.name}-{i}\")\n",
    "\n",
    "else:\n",
    "    raise FileNotFoundError(\"No Top Shelf files found. Rename to include 'top' and 'shelf', or adjust the filters.\")\n",
    "\n",
    "print(\"Using files:\", used_files)\n",
    "print(f\"Built {len(records)} Top Shelf records.\")\n",
    "print(\"Example:\\n\", (records[0]['text'][:500] if records else \"NO RECORDS\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36045f80",
   "metadata": {},
   "source": [
    "Cell C ‚Äî embed in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install openai numpy tiktoken\n",
    "\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "client = OpenAI()  # uses OPENAI_API_KEY\n",
    "\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "MAX_DOCS = min(200, len(records))\n",
    "docs = records[:MAX_DOCS]\n",
    "doc_texts = [d[\"text\"] for d in docs]\n",
    "doc_ids   = [d[\"id\"]   for d in docs]\n",
    "\n",
    "def embed_texts(texts):\n",
    "    vecs = []\n",
    "    for t in texts:\n",
    "        e = client.embeddings.create(model=EMBEDDING_MODEL, input=t).data[0].embedding\n",
    "        vecs.append(np.array(e, dtype=np.float32))\n",
    "    return np.vstack(vecs)\n",
    "\n",
    "print(f\"Embedding {len(doc_texts)} docs‚Ä¶\")\n",
    "doc_vecs = embed_texts(doc_texts)\n",
    "doc_vecs = doc_vecs / (np.linalg.norm(doc_vecs, axis=1, keepdims=True) + 1e-12)\n",
    "print(\"Embeddings shape:\", doc_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5f3710",
   "metadata": {},
   "source": [
    "Cell D: Ask RAG question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb53dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER:\n",
      " A well known Jazz record in the collection is \"Kind of Blue\" by Miles Davis. \n",
      "\n",
      "TOP HITS:\n",
      "- The_Top_Shelf_Collection_RAG_with_artist_years_filled.csv-24 | score=0.476 | Artist: Django Reinhardt | Title: First Recordings | Genre: Jazz/Gypsy Jazz‚Ä¶\n",
      "- The_Top_Shelf_Collection_RAG_with_artist_years_filled.csv-34 | score=0.450 | Artist: Ella Fitzgerald | Title: sings the George and Ira Gershwin Song Book | Genre: Jazz/Vocal Standards‚Ä¶\n",
      "- The_Top_Shelf_Collection_RAG_with_artist_years_filled.csv-56 | score=0.444 | Artist: Miles Davis | Title: Nefertiti | Genre: Jazz‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "gitans, hits = answer_with_context(\n",
    "    \"What's a well known Jazz record in the collection?\",\n",
    "    k=5\n",
    ")\n",
    "print(\"ANSWER:\\n\", ans, \"\\n\")\n",
    "print(\"TOP HITS:\")\n",
    "for hid, htxt, score in hits[:3]:\n",
    "    print(f\"- {hid} | score={score:.3f} | {htxt[:160]}‚Ä¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cd15ff",
   "metadata": {},
   "source": [
    "Testing filtered questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24e3ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAZZ ANSWER:\n",
      " No matching documents in the specified filters. \n",
      "\n",
      "\n",
      "1980s ANSWER:\n",
      " No matching documents in the specified filters. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If you haven't already run the structured + filtered versions, paste these 2 helpers first:\n",
    "\n",
    "def mask_by_filters(meta, year_min=None, year_max=None, genre_contains=None):\n",
    "    import numpy as np, pandas as pd\n",
    "    m = np.ones(len(meta), dtype=bool)\n",
    "    if year_min is not None:\n",
    "        m &= np.array([(r.get(\"year\") is not None and r[\"year\"] >= year_min) for r in meta])\n",
    "    if year_max is not None:\n",
    "        m &= np.array([(r.get(\"year\") is not None and r[\"year\"] <= year_max) for r in meta])\n",
    "    if genre_contains:\n",
    "        gsub = genre_contains.lower()\n",
    "        m &= np.array([gsub in (r.get(\"genre\") or \"\").lower() for r in meta])\n",
    "    return m\n",
    "\n",
    "def top_k_filtered(query, k=5, year_min=None, year_max=None, genre_contains=None):\n",
    "    import numpy as np\n",
    "    q = client.embeddings.create(model=EMBEDDING_MODEL, input=query).data[0].embedding\n",
    "    q = np.array(q, dtype=np.float32)\n",
    "    q = q / (np.linalg.norm(q) + 1e-12)\n",
    "\n",
    "    mask = mask_by_filters(docs_meta if 'docs_meta' in globals() else records, year_min, year_max, genre_contains)\n",
    "    if not mask.any():\n",
    "        return []\n",
    "    sub_vecs = doc_vecs[mask]\n",
    "    sims = sub_vecs @ q\n",
    "    idxs_local = np.argsort(-sims)[:k]\n",
    "    global_idxs = np.flatnonzero(mask)[idxs_local]\n",
    "    texts = [doc_texts[i] for i in global_idxs]\n",
    "    metas = [(docs_meta if 'docs_meta' in globals() else records)[i] for i in global_idxs]\n",
    "    ids = [doc_ids[i] for i in global_idxs]\n",
    "    scores = [float(doc_vecs[i] @ q) for i in global_idxs]\n",
    "    return list(zip(ids, texts, metas, scores))\n",
    "\n",
    "def answer_with_context_filtered(query, k=5, year_min=None, year_max=None, genre_contains=None, temperature=0.2):\n",
    "    hits = top_k_filtered(query, k=k, year_min=year_min, year_max=year_max, genre_contains=genre_contains)\n",
    "    if not hits:\n",
    "        return \"No matching documents in the specified filters.\", []\n",
    "    context = \"\\n\\n\".join(f\"- {h[1]}\" for h in hits)\n",
    "    prompt = (\n",
    "        \"Answer strictly using the CONTEXT below. If the answer is not in the context, say you don't know.\\n\\n\"\n",
    "        f\"CONTEXT:\\n{context}\\n\\nQUESTION: {query}\\n\\nANSWER:\"\n",
    "    )\n",
    "    resp = client.chat.completions.create(\n",
    "        model=CHAT_MODEL if 'CHAT_MODEL' in globals() else \"gpt-4o-mini\",\n",
    "        temperature=temperature,\n",
    "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip(), hits\n",
    "\n",
    "# --- Queries ---\n",
    "ans1, hits1 = answer_with_context_filtered(\n",
    "    \"What's a standout jazz album here, and what makes it notable?\",\n",
    "    k=5, genre_contains=\"jazz\"\n",
    ")\n",
    "print(\"JAZZ ANSWER:\\n\", ans1, \"\\n\")\n",
    "for _id, _txt, meta, score in hits1[:3]:\n",
    "    print(f\"- {meta.get('artist','?')} ‚Äî {meta.get('title','?')} ({meta.get('year')}), [{meta.get('genre','?')}]  score={score:.3f}\")\n",
    "\n",
    "ans2, hits2 = answer_with_context_filtered(\n",
    "    \"Give me one notable album from the 1980s with a brief reason it's notable.\",\n",
    "    k=5, year_min=1980, year_max=1989\n",
    ")\n",
    "print(\"\\n1980s ANSWER:\\n\", ans2, \"\\n\")\n",
    "for _id, _txt, meta, score in hits2[:3]:\n",
    "    print(f\"- {meta.get('artist','?')} ‚Äî {meta.get('title','?')} ({meta.get('year')}), [{meta.get('genre','?')}]  score={score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88069b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 129\n",
      "Example record: {'id': 'The_Top_Shelf_Collection_RAG_with_artist_years_filled.csv-0', 'text': 'Artist: 10,000 Maniacs | Title: In My Tribe | Genre: Alternative Rock'}\n",
      "Meta keys: ['id', 'text']\n",
      "\n",
      "Top genres:\n",
      " Series([], Name: count, dtype: int64)\n",
      "\n",
      "Year stats: count= 0 min= None max= None\n",
      "\n",
      "Matches 'jazz' in genre: 0\n",
      "Matches year 1980‚Äì1989: 0\n"
     ]
    }
   ],
   "source": [
    "import re, numpy as np, pandas as pd\n",
    "\n",
    "# figure out which set we have in memory\n",
    "if 'docs_meta' in globals():\n",
    "    META = docs_meta\n",
    "elif 'structured_records' in globals():\n",
    "    META = structured_records\n",
    "elif 'records' in globals():\n",
    "    META = records\n",
    "else:\n",
    "    raise RuntimeError(\"No records in memory. Re-run your build records cell.\")\n",
    "\n",
    "print(\"Total records:\", len(META))\n",
    "print(\"Example record:\", META[0])\n",
    "\n",
    "# show available keys on meta dicts\n",
    "keys = sorted({k for m in META for k in m.keys()})\n",
    "print(\"Meta keys:\", keys)\n",
    "\n",
    "# genre distribution (lowercased)\n",
    "genres = [ (m.get('genre') or '').strip().lower() for m in META ]\n",
    "unique_genres = pd.Series([g for g in genres if g]).value_counts().head(20)\n",
    "print(\"\\nTop genres:\\n\", unique_genres)\n",
    "\n",
    "# year stats\n",
    "years = [ m.get('year') for m in META ]\n",
    "years_num = [ int(y) for y in years if isinstance(y,int) or (isinstance(y,str) and y.isdigit()) ]\n",
    "print(\"\\nYear stats: count=\", len(years_num), \"min=\", min(years_num) if years_num else None, \"max=\", max(years_num) if years_num else None)\n",
    "\n",
    "# counts for our two target filters\n",
    "def contains_jazz(m):\n",
    "    g = (m.get('genre') or '').lower()\n",
    "    return 'jazz' in g\n",
    "\n",
    "def in_80s(m):\n",
    "    y = m.get('year')\n",
    "    try:\n",
    "        y = int(y)\n",
    "        return 1980 <= y <= 1989\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "print(\"\\nMatches 'jazz' in genre:\", sum(contains_jazz(m) for m in META))\n",
    "print(\"Matches year 1980‚Äì1989:\", sum(in_80s(m) for m in META))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2721b2",
   "metadata": {},
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71dd877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed docs_meta sample: {'artist': '10,000 Maniacs', 'title': 'In My Tribe', 'genre': 'Alternative Rock', 'year': None, 'id': 'The_Top_Shelf_Collection_RAG_with_artist_years_filled.csv-0', 'text': 'Artist: 10,000 Maniacs | Title: In My Tribe | Genre: Alternative Rock'}\n",
      "Keys present: ['artist', 'genre', 'id', 'text', 'title', 'year']\n",
      "Genre examples: ['alternative rock', 'alternative rock/art rock', 'alternative rock/folk rock', 'alternative rock/new wave', 'blues/soul', 'christmas', 'classic rock', 'classical', 'country/folk', 'disco/funk']\n",
      "Year min/max: (1958, 1994)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "assert 'records' in globals() and len(records) > 0, \"No records found. Re-run the build-records cell first.\"\n",
    "\n",
    "def parse_kv_text(txt: str):\n",
    "    \"\"\"\n",
    "    Parses strings like:\n",
    "      'Artist: 10,000 Maniacs | Title: In My Tribe | Genre: Alternative Rock | Year: 1987'\n",
    "    into a dict {'artist': '10,000 Maniacs', 'title': 'In My Tribe', 'genre': 'Alternative Rock', 'year': 1987}\n",
    "    Falls back to regex for year if no explicit 'Year:' field.\n",
    "    \"\"\"\n",
    "    fields = {}\n",
    "    # split on ' | ' chunks, then split on the first ':'\n",
    "    for chunk in txt.split('|'):\n",
    "        chunk = chunk.strip()\n",
    "        if ':' in chunk:\n",
    "            k, v = chunk.split(':', 1)\n",
    "            k = k.strip().lower()\n",
    "            v = v.strip()\n",
    "            fields[k] = v\n",
    "\n",
    "    # normalize keys we care about\n",
    "    artist = fields.get('artist', '') or fields.get('band', '') or ''\n",
    "    title  = fields.get('title', '')  or fields.get('album', '') or ''\n",
    "    genre  = fields.get('genre', '')  or fields.get('style', '') or ''\n",
    "\n",
    "    # year: prefer explicit, else extract first 4-digit 19xx/20xx\n",
    "    year_str = fields.get('year', '')\n",
    "    year = None\n",
    "    if year_str:\n",
    "        m = re.search(r'(?<!\\d)(19|20)\\d{2}(?!\\d)', year_str)\n",
    "        if m:\n",
    "            year = int(m.group(0))\n",
    "    if year is None:\n",
    "        m2 = re.search(r'(?<!\\d)(19|20)\\d{2}(?!\\d)', txt)\n",
    "        if m2:\n",
    "            year = int(m2.group(0))\n",
    "\n",
    "    return {\n",
    "        'artist': artist,\n",
    "        'title': title,\n",
    "        'genre': genre,\n",
    "        'year': year\n",
    "    }\n",
    "\n",
    "# Build parsed metadata aligned to your existing vectors/texts if present\n",
    "if 'doc_texts' in globals() and 'doc_ids' in globals():\n",
    "    base_texts = doc_texts\n",
    "    base_ids   = doc_ids\n",
    "else:\n",
    "    base_texts = [r['text'] for r in records]\n",
    "    base_ids   = [r['id']   for r in records]\n",
    "\n",
    "docs_meta = []\n",
    "for rid, txt in zip(base_ids, base_texts):\n",
    "    meta = parse_kv_text(txt)\n",
    "    meta['id'] = rid\n",
    "    meta['text'] = txt\n",
    "    docs_meta.append(meta)\n",
    "\n",
    "print(\"Parsed docs_meta sample:\", docs_meta[0])\n",
    "print(\"Keys present:\", sorted(docs_meta[0].keys()))\n",
    "\n",
    "# Quick stats\n",
    "genres_lower = [ (m.get('genre') or '').lower() for m in docs_meta ]\n",
    "years = [ m.get('year') for m in docs_meta if m.get('year') is not None ]\n",
    "print(\"Genre examples:\", sorted(set(g for g in genres_lower if g))[:10])\n",
    "print(\"Year min/max:\", (min(years), max(years)) if years else (None, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd632362",
   "metadata": {},
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9284fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, re\n",
    "\n",
    "# Ensure vectors exist\n",
    "assert 'doc_vecs' in globals(), \"No embeddings found. Re-run your embedding cell (C / C2) first.\"\n",
    "\n",
    "TEXTS = [m[\"text\"] for m in docs_meta]\n",
    "IDS   = [m[\"id\"]   for m in docs_meta]\n",
    "VECS  = doc_vecs   # from your embedding step\n",
    "\n",
    "def infer_year_from_text(t):\n",
    "    m = re.search(r'(?<!\\d)(19|20)\\d{2}(?!\\d)', t)\n",
    "    return int(m.group(0)) if m else None\n",
    "\n",
    "def genre_matches(meta, text, want):\n",
    "    g = (meta.get(\"genre\") or \"\").lower()\n",
    "    if want.lower() in g:\n",
    "        return True\n",
    "    return want.lower() in text.lower()\n",
    "\n",
    "def year_in_range(meta, text, lo=None, hi=None):\n",
    "    if lo is None and hi is None:\n",
    "        return True\n",
    "    y = meta.get(\"year\")\n",
    "    try:\n",
    "        y = int(y)\n",
    "    except:\n",
    "        y = infer_year_from_text(text)\n",
    "    if y is None:\n",
    "        return False\n",
    "    return (lo if lo is not None else -10**9) <= y <= (hi if hi is not None else 10**9)\n",
    "\n",
    "def mask_by_filters_forgiving(year_min=None, year_max=None, genre_contains=None):\n",
    "    m = np.ones(len(TEXTS), dtype=bool)\n",
    "    if genre_contains:\n",
    "        m &= np.array([genre_matches(docs_meta[i], TEXTS[i], genre_contains) for i in range(len(TEXTS))])\n",
    "    if year_min is not None or year_max is not None:\n",
    "        m &= np.array([year_in_range(docs_meta[i], TEXTS[i], year_min, year_max) for i in range(len(TEXTS))])\n",
    "    return m\n",
    "\n",
    "def top_k_filtered_forgiving(query, k=5, year_min=None, year_max=None, genre_contains=None):\n",
    "    qv = client.embeddings.create(model=EMBEDDING_MODEL, input=query).data[0].embedding\n",
    "    qv = np.array(qv, dtype=np.float32)\n",
    "    qv = qv / (np.linalg.norm(qv) + 1e-12)\n",
    "\n",
    "    mask = mask_by_filters_forgiving(year_min, year_max, genre_contains)\n",
    "    if not mask.any():\n",
    "        return []\n",
    "\n",
    "    sub_vecs = VECS[mask]\n",
    "    sims = sub_vecs @ qv\n",
    "    idxs_local = np.argsort(-sims)[:k]\n",
    "    global_idxs = np.flatnonzero(mask)[idxs_local]\n",
    "\n",
    "    return [(IDS[i], TEXTS[i], docs_meta[i], float(VECS[i] @ qv)) for i in global_idxs]\n",
    "\n",
    "def answer_with_context_filtered_forgiving(query, k=5, year_min=None, year_max=None, genre_contains=None, temperature=0.2):\n",
    "    hits = top_k_filtered_forgiving(query, k, year_min, year_max, genre_contains)\n",
    "    if not hits:\n",
    "        return \"No matching documents in the specified filters.\", []\n",
    "    context = \"\\n\\n\".join(f\"- {h[1]}\" for h in hits)\n",
    "    prompt = (\n",
    "        \"Answer strictly using the CONTEXT below. If the answer is not in the context, say you don't know.\\n\\n\"\n",
    "        f\"CONTEXT:\\n{context}\\n\\nQUESTION: {query}\\n\\nANSWER:\"\n",
    "    )\n",
    "    resp = client.chat.completions.create(\n",
    "        model=CHAT_MODEL if 'CHAT_MODEL' in globals() else \"gpt-4o-mini\",\n",
    "        temperature=temperature,\n",
    "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip(), hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d5994",
   "metadata": {},
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c67b193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAZZ ANSWER:\n",
      " I don't know. \n",
      "\n",
      "- The Dave Brubeck Quartet ‚Äî Red Hot and Cool (None), [Jazz]  score=0.443\n",
      "- Miles Davis ‚Äî Kind of Blue (None), [Jazz]  score=0.437\n",
      "- Dave Brubeck Quartet ‚Äî Time Out (None), [Jazz]  score=0.431\n",
      "\n",
      "1980s ANSWER:\n",
      " I don't know. \n",
      "\n",
      "- Cheap Trick ‚Äî The Epic Archive Vol. 2 (1980-1983) (1980), [Rock]  score=0.348\n",
      "- Cheap Trick ‚Äî The Epic Archive Vol. 3 (1984-1992) (1984), [Rock]  score=0.337\n"
     ]
    }
   ],
   "source": [
    "ans1, hits1 = answer_with_context_filtered_forgiving(\n",
    "    \"What's a standout jazz album here, and what makes it notable?\",\n",
    "    k=5, genre_contains=\"jazz\"\n",
    ")\n",
    "print(\"JAZZ ANSWER:\\n\", ans1, \"\\n\")\n",
    "for _id, _txt, meta, score in hits1[:3]:\n",
    "    print(f\"- {meta.get('artist','?')} ‚Äî {meta.get('title','?')} ({meta.get('year')}), [{meta.get('genre','?')}]  score={score:.3f}\")\n",
    "\n",
    "ans2, hits2 = answer_with_context_filtered_forgiving(\n",
    "    \"Give me one notable album from the 1980s with a brief reason it's notable.\",\n",
    "    k=5, year_min=1980, year_max=1989\n",
    ")\n",
    "print(\"\\n1980s ANSWER:\\n\", ans2, \"\\n\")\n",
    "for _id, _txt, meta, score in hits2[:3]:\n",
    "    print(f\"- {meta.get('artist','?')} ‚Äî {meta.get('title','?')} ({meta.get('year')}), [{meta.get('genre','?')}]  score={score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba77eec",
   "metadata": {},
   "source": [
    "clean, reliable queries without needing descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2df503d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 129\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10,000 Maniacs</td>\n",
       "      <td>In My Tribe</td>\n",
       "      <td>Alternative Rock</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy Winehouse</td>\n",
       "      <td>Back to Black</td>\n",
       "      <td>Soul/Jazz</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Average White Band</td>\n",
       "      <td>Volume IIIV</td>\n",
       "      <td>Funk/Soul</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Billy Joel</td>\n",
       "      <td>52nd Street</td>\n",
       "      <td>Pop Rock</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black Pumas</td>\n",
       "      <td></td>\n",
       "      <td>Soul/Funk</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               artist          title             genre  year\n",
       "0      10,000 Maniacs    In My Tribe  Alternative Rock  <NA>\n",
       "1       Amy Winehouse  Back to Black         Soul/Jazz  <NA>\n",
       "2  Average White Band    Volume IIIV         Funk/Soul  <NA>\n",
       "3          Billy Joel    52nd Street          Pop Rock  <NA>\n",
       "4         Black Pumas                        Soul/Funk  <NA>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚Äî Jazz entries (first 10) ‚Äî\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amy Winehouse</td>\n",
       "      <td>Back to Black</td>\n",
       "      <td>Soul/Jazz</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Carmen McRae-Dave Brubeck</td>\n",
       "      <td>Take Five, Recorded Live at Basin Street East</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Django Reinhardt</td>\n",
       "      <td>First Recordings</td>\n",
       "      <td>Jazz/Gypsy Jazz</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ella Fitzgerald</td>\n",
       "      <td>sings the George and Ira Gershwin Song Book</td>\n",
       "      <td>Jazz/Vocal Standards</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Madeleine Peyroux</td>\n",
       "      <td>Careless Love</td>\n",
       "      <td>Jazz/Blues</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Miles Davis</td>\n",
       "      <td>Nefertiti</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Nina Simone</td>\n",
       "      <td>Sings Her Greatest Hits</td>\n",
       "      <td>Jazz /Blues</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Ray Charles</td>\n",
       "      <td>The Great Ray Charles</td>\n",
       "      <td>Soul/Jazz</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Rosa Passos &amp; Ron Carter</td>\n",
       "      <td>Entre Amigos</td>\n",
       "      <td>Jazz Bossa Nova</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Stan Getz</td>\n",
       "      <td>Cafe Montmartre</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       artist                                          title  \\\n",
       "1               Amy Winehouse                                  Back to Black   \n",
       "17  Carmen McRae-Dave Brubeck  Take Five, Recorded Live at Basin Street East   \n",
       "24           Django Reinhardt                               First Recordings   \n",
       "34            Ella Fitzgerald    sings the George and Ira Gershwin Song Book   \n",
       "53          Madeleine Peyroux                                  Careless Love   \n",
       "56                Miles Davis                                      Nefertiti   \n",
       "58                Nina Simone                        Sings Her Greatest Hits   \n",
       "66                Ray Charles                          The Great Ray Charles   \n",
       "70   Rosa Passos & Ron Carter                                   Entre Amigos   \n",
       "75                  Stan Getz                                Cafe Montmartre   \n",
       "\n",
       "                   genre  year  \n",
       "1              Soul/Jazz  <NA>  \n",
       "17                  Jazz  <NA>  \n",
       "24       Jazz/Gypsy Jazz  <NA>  \n",
       "34  Jazz/Vocal Standards  <NA>  \n",
       "53            Jazz/Blues  <NA>  \n",
       "56                  Jazz  <NA>  \n",
       "58           Jazz /Blues  <NA>  \n",
       "66             Soul/Jazz  <NA>  \n",
       "70       Jazz Bossa Nova  <NA>  \n",
       "75                  Jazz  <NA>  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚Äî 1980s entries (first 10) ‚Äî\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cheap Trick</td>\n",
       "      <td>The Epic Archive Vol. 2 (1980-1983)</td>\n",
       "      <td>Rock</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cheap Trick</td>\n",
       "      <td>The Epic Archive Vol. 3 (1984-1992)</td>\n",
       "      <td>Rock</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist                                title genre  year\n",
       "19  Cheap Trick  The Epic Archive Vol. 2 (1980-1983)  Rock  1980\n",
       "20  Cheap Trick  The Epic Archive Vol. 3 (1984-1992)  Rock  1984"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚Äî Search artist contains 'miles' ‚Äî\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Miles Davis</td>\n",
       "      <td>Nefertiti</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Miles Davis</td>\n",
       "      <td>Kind of Blue</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist         title genre  year\n",
       "56   Miles Davis     Nefertiti  Jazz  <NA>\n",
       "128  Miles Davis  Kind of Blue  Jazz  <NA>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, re\n",
    "\n",
    "# Build a small DataFrame from the parsed metadata if you have docs_meta; else, parse records again.\n",
    "def to_df_from_docs_meta(docs_meta):\n",
    "    rows = []\n",
    "    for m in docs_meta:\n",
    "        rows.append({\n",
    "            \"artist\": m.get(\"artist\") or \"\",\n",
    "            \"title\":  m.get(\"title\") or \"\",\n",
    "            \"genre\":  m.get(\"genre\") or \"\",\n",
    "            \"year\":   m.get(\"year\"),\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    # clean year\n",
    "    df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "def parse_from_records(records):\n",
    "    # fallback parser if docs_meta doesn't exist\n",
    "    import re\n",
    "    def parse_kv_text(txt):\n",
    "        fields = {}\n",
    "        for chunk in txt.split(\"|\"):\n",
    "            chunk = chunk.strip()\n",
    "            if \":\" in chunk:\n",
    "                k,v = chunk.split(\":\",1)\n",
    "                fields[k.strip().lower()] = v.strip()\n",
    "        artist = fields.get(\"artist\",\"\")\n",
    "        title  = fields.get(\"title\",\"\")\n",
    "        genre  = fields.get(\"genre\",\"\")\n",
    "        # year inference\n",
    "        y = fields.get(\"year\",\"\")\n",
    "        m = re.search(r'(?<!\\d)(19|20)\\d{2}(?!\\d)', y or txt)\n",
    "        year = int(m.group(0)) if m else None\n",
    "        return {\"artist\":artist, \"title\":title, \"genre\":genre, \"year\":year}\n",
    "    rows = [parse_kv_text(r[\"text\"]) for r in records]\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "if 'docs_meta' in globals():\n",
    "    lib = to_df_from_docs_meta(docs_meta)\n",
    "else:\n",
    "    lib = parse_from_records(records)\n",
    "\n",
    "print(\"Rows:\", len(lib))\n",
    "display(lib.head(5))\n",
    "\n",
    "def list_by_genre(genre_sub, limit=10):\n",
    "    mask = lib[\"genre\"].str.contains(genre_sub, case=False, na=False)\n",
    "    return lib[mask].dropna(how=\"all\").head(limit)\n",
    "\n",
    "def list_by_year_range(ymin=None, ymax=None, limit=10):\n",
    "    df = lib.copy()\n",
    "    if ymin is not None:\n",
    "        df = df[df[\"year\"].notna() & (df[\"year\"] >= ymin)]\n",
    "    if ymax is not None:\n",
    "        df = df[df[\"year\"].notna() & (df[\"year\"] <= ymax)]\n",
    "    return df.head(limit)\n",
    "\n",
    "def search_artist(substr, limit=10):\n",
    "    return lib[lib[\"artist\"].str.contains(substr, case=False, na=False)].head(limit)\n",
    "\n",
    "# Examples (adjust freely)\n",
    "print(\"\\n‚Äî Jazz entries (first 10) ‚Äî\")\n",
    "display(list_by_genre(\"jazz\", 10))\n",
    "\n",
    "print(\"\\n‚Äî 1980s entries (first 10) ‚Äî\")\n",
    "display(list_by_year_range(1980, 1989, 10))\n",
    "\n",
    "print(\"\\n‚Äî Search artist contains 'miles' ‚Äî\")\n",
    "display(search_artist(\"miles\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716828c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
